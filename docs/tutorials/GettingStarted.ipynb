{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with AutoProf\n",
    "\n",
    "In this notebook you will walk through the very basics of AutoProf functionality. Here you will learn how to make models; how to set them up for fitting; and how to view the results. These core elements will come up every time you use AutoProf, though in future notebooks you will learn how to take advantage of the advanced features in AutoProf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import autoprof as ap\n",
    "import numpy as np\n",
    "import torch\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your first model\n",
    "\n",
    "The basic format for making an AutoProf model is given below. Once a model object is constructed, it can be manipulated and updated in various ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = ap.models.AutoProf_Model(\n",
    "    name = \"model1\", # every model must have a unique name\n",
    "    model_type = \"sersic galaxy model\", # this specifies the kind of model\n",
    "    parameters = {\"center\": [50,50], \"q\": 0.6, \"PA\": 60*np.pi/180, \"n\": 2, \"Re\": 10, \"Ie\": 1}, # here we set initial values for each parameter\n",
    ")\n",
    "model1.initialize() # before using the model it is good practice to call initialize so the model can get itself ready\n",
    "\n",
    "# We can print the model's basic info\n",
    "print(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoProf has built in methods to plot relevant information. We didn't specify the region on the sky for\n",
    "# this model to focus on, so by default it just makes a 100x100 window. Unless you are very lucky this wont\n",
    "# line up with what you're trying to fit, so next we'll see how to give the model a target.\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (8,8))\n",
    "ap.plots.model_image(fig, ax, model1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giving the model a Target\n",
    "\n",
    "Typically, the main goal when constructing an AutoProf model is to fit to an image. We need to give the model access to the image and some information about it to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's download an image to play with\n",
    "hdu = fits.open(\"https://www.legacysurvey.org/viewer/fits-cutout?ra=36.3684&dec=-25.6389&size=700&layer=ls-dr9&pixscale=0.262&bands=r\")\n",
    "target_data = np.array(hdu[0].data, dtype = np.float64)\n",
    "\n",
    "# Create a target object with specified pixelscale and zeropoint\n",
    "target = ap.image.Target_Image(\n",
    "    data = target_data,\n",
    "    pixelscale = 0.262, # Every target image needs to know it's pixelscale in arcsec/pixel\n",
    "    zeropoint = 22.5, # optionally you can give a zeropoint to tell AutoProf what the pixel flux units are\n",
    ")\n",
    "\n",
    "# The default AutoProf target plotting method uses log scaling in bright areas and histogram scaling in faint areas\n",
    "fig3, ax3 = plt.subplots(figsize = (8,8))\n",
    "ap.plots.target_image(fig3, ax3, target)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model now has a target that it will attempt to match\n",
    "model2 = ap.models.AutoProf_Model(\n",
    "    name = \"model with target\", \n",
    "    model_type = \"sersic galaxy model\",\n",
    "    target = target, # now the model knows what its trying to match\n",
    ")\n",
    "\n",
    "# Instead of giving initial values for all the parameters, it is possible to simply call \"initialize\" and AutoProf \n",
    "# will try to guess initial values for every parameter assuming the galaxy is roughly centered. It is also possible\n",
    "# to set just a few parameters and let AutoProf try to figure out the rest. For example you could give it an initial\n",
    "# Guess for the center and it will work from there.\n",
    "model2.initialize()\n",
    "\n",
    "# Plotting the initial parameters and residuals, we see it gets the rough shape of the galaxy right, but still has some fitting to do\n",
    "fig4, ax4 = plt.subplots(1, 2, figsize = (16,7))\n",
    "ap.plots.model_image(fig4, ax4[0], model2)\n",
    "ap.plots.residual_image(fig4, ax4[1], model2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that the model has been set up with a target and initialized with parameter values, it is time to fit the image\n",
    "result = ap.fit.LM(model2, method = 4, verbose = 1).fit()\n",
    "# See that we use ap.fit.LM, this is the Levenberg-Marquardt Chi^2 minimization method, it is the recommended technique\n",
    "# for most least-squares problems. However, there are situations in which different optimizers may be more desireable\n",
    "# so the ap.fit package includes a few options to pick from. The various fitting methods will be described in a \n",
    "# different tutorial.\n",
    "print(result.message) # the fitter will return a message about its convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now plot the fitted model and the image residuals\n",
    "fig5, ax5 = plt.subplots(1, 2, figsize = (16,7))\n",
    "ap.plots.model_image(fig5, ax5[0], model2)\n",
    "ap.plots.residual_image(fig5, ax5[1], model2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giving the model a specific target window\n",
    "\n",
    "Sometimes an object isn't nicely centered in the image, and may not even be the dominant object in the image. It is therefore nice to be able to specify what part of the image we should analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = ap.models.AutoProf_Model(\n",
    "    name = \"model with target\", \n",
    "    model_type = \"sersic galaxy model\",\n",
    "    target = target,\n",
    "    window = [[480, 590],[555, 665]], # this is a region in pixel coordinates ((xmin,xmax),(ymin,ymax)) \n",
    ")\n",
    "\n",
    "# We can plot the \"model window\" to show us what part of the image will be analyzed by that model\n",
    "fig6, ax6 = plt.subplots(figsize = (8,8))\n",
    "ap.plots.model_window(fig6, ax6, model3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.initialize()\n",
    "result = ap.fit.LM(model3, method = 4, verbose = 1).fit()\n",
    "print(result.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that when only a window is fit, the default plotting methods will only show that window\n",
    "fig7, ax7 = plt.subplots(1, 2, figsize = (16,7))\n",
    "ap.plots.model_image(fig7, ax7[0], model3)\n",
    "ap.plots.residual_image(fig7, ax7[1], model3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting parameter constraints\n",
    "\n",
    "A common feature of fitting parameters is that they have some constraint on their behaviour and cannot be sampled at any value from (-inf, inf). AutoProf circumvents this by remapping any constrained parameter to a space where it can take any real value, at least for the sake of fitting. For most parameters these constraints are applied by default; for example the axis ratio q is required to be in the range (0,1). Other parameters, such as the position angle (PA) are cyclic, they can be in the range (0,pi) but also can wrap around. It is possible to manually set these constraints while constructing a model.\n",
    "\n",
    "In general adding constraints makes fitting more difficult. There is a chance that the fitting process runs up against a constraint boundary and gets stuck. However, sometimes adding constraints is necessary and so the capability is included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we make a sersic model that can only have q and n in a narrow range\n",
    "# Also, we give PA and initial value and lock that so it does not change during fitting\n",
    "constrained_param_model = ap.models.AutoProf_Model(\n",
    "    name = \"constrained parameters\", model_type = \"sersic galaxy model\", \n",
    "    parameters = {\n",
    "        \"q\": {\"limits\": [0.4,0.6]}, \n",
    "        \"n\": {\"limits\": [2,3]}, \n",
    "        \"PA\": {\"value\": 60*np.pi/180, \"locked\": True},\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside from constraints on an individual parameter, it is sometimes desireable to have different models share parameter values. For example you may wish to combine multiple simple models into a more complex model (more on that in a different tutorial), and you may wish for them all to have the same center. This can be accomplished with \"equality constraints\" as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 1 is a sersic model\n",
    "model_1 = ap.models.AutoProf_Model(\n",
    "    name = \"constrained 1\",\n",
    "    model_type = \"sersic galaxy model\",\n",
    "    parameters = {\"center\": [50,50], \"PA\": np.pi/4}\n",
    ")\n",
    "# model 2 is an exponential model\n",
    "model_2 = ap.models.AutoProf_Model(\n",
    "    name = \"constrained 2\",\n",
    "    model_type = \"exponential galaxy model\",\n",
    ")\n",
    "\n",
    "# Here we add the constraint for \"PA\" to be the same for each model.\n",
    "# In doing so we provide the parameter name and the model which should \n",
    "# be connected.\n",
    "model_2.add_equality_constraint(model_1, \"PA\")\n",
    "\n",
    "# Here we can see how the two models now both can modify this parameter\n",
    "print(\"initial values: model_1 PA\", model_1[\"PA\"].value.item(), \"model_2 PA\", model_2[\"PA\"].value.item())\n",
    "# Now we modify the PA for model_1\n",
    "model_1[\"PA\"].value = np.pi/3\n",
    "print(\"change model_1: model_1 PA\", model_1[\"PA\"].value.item(), \"model_2 PA\", model_2[\"PA\"].value.item())\n",
    "# Similarly we modify the PA for model_2\n",
    "model_2[\"PA\"].value = np.pi/2\n",
    "print(\"change model_2: model_1 PA\", model_1[\"PA\"].value.item(), \"model_2 PA\", model_2[\"PA\"].value.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep in mind that both models have full control over the parameter, it is listed in both of\n",
    "# their \"parameter_order\" tuples. The built-in AutoProf functions keep track of constrained \n",
    "# parameters by asking models if any of their parameters are constrained\n",
    "print(\"model_1 parameters: \", model_1.parameter_order(), \" are any parameter constrained: \", model_1.equality_constraints)\n",
    "print(\"model_2 parameters: \", model_2.parameter_order(), \" are any parameter constrained: \", model_2.equality_constraints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSF convolution\n",
    "\n",
    "An important part of astronomical image analysis is accounting for PSF effects. To that end, AutoProf includes a number of approaches to handle PSF convolution. The main concept is that AutoProf will convolve its model with a PSF before comparing against an image. The PSF behaviour of a model is determined by the *psf_mode* parameter which can be set before fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first a psf is needed, this is stored with the target object\n",
    "# Here we simply construct a gaussian PSF image that is 31 pixels across\n",
    "# Note the PSF must always be odd in its dimensions\n",
    "xx, yy = np.meshgrid(np.linspace(-5,5,31), np.linspace(-5,5,31))\n",
    "PSF = np.exp(-(xx**2 + yy**2)/5**2)\n",
    "PSF /= np.sum(PSF)\n",
    "target = ap.image.Target_Image(\n",
    "    data = target_data,\n",
    "    pixelscale = 0.262,\n",
    "    zeropoint = 22.5,\n",
    "    psf = PSF,\n",
    ")\n",
    "\n",
    "model_nopsf = ap.models.AutoProf_Model(\n",
    "    name = \"model without psf\", \n",
    "    model_type = \"sersic galaxy model\",\n",
    "    target = target,\n",
    "    parameters = {\"center\": [90,90], \"q\": 0.6, \"PA\": 60*np.pi/180, \"n\": 2, \"Re\": 10, \"Ie\": 1},\n",
    "    psf_mode = \"none\", # no PSF convolution will be done\n",
    ")\n",
    "model_psf = ap.models.AutoProf_Model(\n",
    "    name = \"model with psf\", \n",
    "    model_type = \"sersic galaxy model\",\n",
    "    target = target,\n",
    "    parameters = {\"center\": [90,90], \"q\": 0.6, \"PA\": 60*np.pi/180, \"n\": 2, \"Re\": 10, \"Ie\": 1},\n",
    "    psf_mode = \"full\", # now the full window will be PSF convolved\n",
    ")\n",
    "print(\"psf mode: \", model_psf.psf_mode)\n",
    "\n",
    "# With a convolved sersic the center is much more smoothed out\n",
    "fig, ax = plt.subplots(1,2,figsize = (16,7))\n",
    "ap.plots.model_image(fig, ax[0], model_nopsf)\n",
    "ax[0].set_title(\"No PSF convolution\")\n",
    "ap.plots.model_image(fig, ax[1], model_psf)\n",
    "ax[1].set_title(\"With PSF convolution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic things to do with a model\n",
    "\n",
    "Now that we know how to create a model and fit it to an image, lets get to know the model a bit better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "\n",
    "model2.save() # will default to save as AutoProf.yaml\n",
    "with open(\"AutoProf.yaml\", \"r\") as f:\n",
    "    print(f.read()) # show what the saved file looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a model from a file\n",
    "\n",
    "# note that the target still must be specified, only the parameters are saved\n",
    "model4 = ap.models.AutoProf_Model(name = \"no name\", filename = \"AutoProf.yaml\", target = target)\n",
    "print(model4) # can see that it has been constructed with all the same parameters as the saved model2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model image to a file\n",
    "\n",
    "model2.sample().save(\"model2.fits\")\n",
    "\n",
    "saved_image_hdu = fits.open(\"model2.fits\")\n",
    "fig, ax = plt.subplots(figsize = (8,8))\n",
    "ax.imshow(\n",
    "    np.log10(saved_image_hdu[0].data), \n",
    "    origin = \"lower\",\n",
    "    cmap = ap.plots.visuals.cmap_grad, # gradient colourmap default for AutoProf\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load a target image\n",
    "\n",
    "target.save(\"target.fits\")\n",
    "\n",
    "new_target = ap.image.Target_Image(filename = \"target.fits\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (8,8))\n",
    "ap.plots.target_image(fig, ax, new_target)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the surface brightness profile\n",
    "\n",
    "fig8, ax8 = plt.subplots(figsize = (8,8))\n",
    "ap.plots.galaxy_light_profile(fig8, ax8, model4)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the model new parameter values manually\n",
    "\n",
    "print(\"parameter input order: \", model4.parameter_order) # use this to see what order you have to give the parameters as input\n",
    "\n",
    "# plot the old model\n",
    "fig9, ax9 = plt.subplots(1,2,figsize = (16,7))\n",
    "ap.plots.model_image(fig9, ax9[0], model4)\n",
    "T = ax9[0].set_title(\"parameters as loaded\")\n",
    "\n",
    "# update and plot the new parameters\n",
    "new_parameters = torch.tensor([75, 110, 0.4, 20*np.pi/180, 3, 25, 0.12]) # note that the center parameter needs two values as input\n",
    "model4.initialize() # initialize must be called before optimization, or any other activity in which parameters are updated\n",
    "model4.set_parameters(new_parameters) # full_sample will update the parameters, then run sample and return the model image \n",
    "ap.plots.model_image(fig9, ax9[1], model4)\n",
    "T = ax9[1].set_title(\"new parameter values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the model image pixels directly\n",
    "\n",
    "fig2, ax2 = plt.subplots(figsize = (8,8))\n",
    "\n",
    "pixels = model4.sample().data.detach().cpu().numpy()# model4.model_image.data is the pytorch stored model image pixel values. Calling detach().cpu().numpy() is needed to get the data out of pytorch and in a usable form\n",
    "\n",
    "im = plt.imshow(\n",
    "    np.log10(pixels), # take log10 for better dynamic range\n",
    "    origin = \"lower\",\n",
    "    cmap = ap.plots.visuals.cmap_grad, # gradient colourmap default for AutoProf\n",
    ")\n",
    "plt.colorbar(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models can be constructed by providing model_type, or by creating the desired class directly\n",
    "\n",
    "#                     notice this is no longer \"AutoProf_Model\"\n",
    "model1_v2 = ap.models.Sersic_Galaxy(\n",
    "    name = \"model1 v2\",\n",
    "    parameters = {\"center\": [50,50], \"q\": 0.6, \"PA\": 60*np.pi/180, \"n\": 2, \"Re\": 10, \"Ie\": 1},\n",
    ")\n",
    "\n",
    "# This will be the same as model1\n",
    "print(model1_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using GPU acceleration\n",
    "\n",
    "This one is easy! If you have a cuda enabled GPU available, AutoProf will just automatically detect it and use that device. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if AutoProf has detected your GPU\n",
    "print(ap.models.AutoProf_Model.device) # most likely this will say \"cpu\" unless you already have a cuda GPU, in which case it should say \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have a GPU but want to use the cpu for some reason, just set:\n",
    "ap.models.AutoProf_Model.device = \"cpu\"\n",
    "# before creating your models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
