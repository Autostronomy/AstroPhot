{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Poisson Noise Model\n",
    "\n",
    "For the most part, astronomical images are modelled assuming an independent Gaussian uncertainty on every pixel resulting in a negative log likelihood of the form: $\\sum_i\\frac{(d_i-m_i)^2}{2\\sigma_i^2}$ where $d_i$ is the pixel value, $m_i$ is the model value for that pixel, and $\\sigma_i$ is the uncertainty on that pixel. However, in truth the best model for an astronomical image is the Poisson distribution with negative log likelihood of: $\\sum_i m_i + \\log(d_i!) - d_i\\log(m_i)$ with the same definitions, except specifying that $d_i$ is in counts (number of photons or electrons). For large enough $d_i$ these likelihoods are essentially identical and Gaussian is easier to work with. When signal-to-noise ratios get very low, the differences between Poisson and Gaussian distributions can become apparent and so it is important to treat the data with a Poisson likelihood. These conditions regularly occur for gamma ray, x-ray, and low SNR UV data, but are less common for longer wavelengths. AstroPhot can model Poisson likelihood data, here we will demo an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import astrophot as ap\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Make some mock data\n",
    "\n",
    "Lets create some mock low SNR data. Notice that poisson noise isn't additive like gaussian noise. To sample the image, out true model acts as a photon rate and the `np.random.poisson` samples some number of counts based on that rate. Our goal will be to recover the rate of every pixel and ultimately the sersic parameters that produce the correct rate model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make some mock data\n",
    "target = ap.TargetImage(data=np.zeros((128, 128)))\n",
    "true_model = ap.Model(\n",
    "    name=\"truth\",\n",
    "    model_type=\"sersic galaxy model\",\n",
    "    center=(64, 64),\n",
    "    q=0.7,\n",
    "    PA=0,\n",
    "    n=1,\n",
    "    Re=32,\n",
    "    Ie=1,\n",
    "    target=target,\n",
    ")\n",
    "img = true_model().data.T.detach().cpu().numpy()\n",
    "np.random.seed(42)  # for reproducibility\n",
    "target.data = np.random.poisson(img)  # sample poisson distribution\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ap.plots.model_image(fig, ax[0], true_model)\n",
    "ax[0].set_title(\"True Model\")\n",
    "ap.plots.target_image(fig, ax[1], target)\n",
    "ax[1].set_title(\"Target Image (Poisson Sampled)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "Indeed this is some noisy data. The AstroPhot target_image plotting routine struggles a bit with this image, but it kind of looks neat anyway.\n",
    "\n",
    "## Model the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ap.Model(name=\"model\", model_type=\"sersic galaxy model\", target=target)\n",
    "model.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "While the Levenberg-Marquardt algorithm is traditionally considered as a least squares algorithm, that is actually just its most common application. LM naturally generalizes to a broad class of problems, including the Poisson Likelihood. Here we see the AstroPhot automatic initialization does well on this image and recovers decent starting parameters, LM has an easy time finishing the job to find the maximum likelihood.\n",
    "\n",
    "Note that the idea of a $\\chi^2/{\\rm dof}$ is not as clearly defined for a Poisson likelihood. We take the closest analogue by taking 2 times the negative log likelihood divided by the DoF. This doesn't have any strict statistical meaning but is somewhat intuitive to work with for those used to $\\chi^2/{\\rm dof}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ap.fit.LM(model, likelihood=\"poisson\", verbose=1).fit()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ap.plots.model_image(fig, ax, model)\n",
    "ax.set_title(\"Fitted Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Printing the model and its parameters, we see that we have indeed recovered very close to the true values for all parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "If you encounter a problem where LM struggles to fit the poisson data, the `Slalom` optimizer is also quite efficient in these settings. See the fitting methods tutorial for more details."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
